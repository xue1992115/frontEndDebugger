{"version":3,"file":"kafka.interface.js","sourceRoot":"","sources":["kafka.interface.ts"],"names":[],"mappings":";AAAA;;;;;;;GAOG;;;AAiRH,IAAY,gBAQX;AARD,WAAY,gBAAgB;IAC1B,6DAAW,CAAA;IACX,qDAAO,CAAA;IACP,yDAAS,CAAA;IACT,yDAAS,CAAA;IACT,6DAAW,CAAA;IACX,+EAAoB,CAAA;IACpB,+EAAoB,CAAA;AACtB,CAAC,EARW,gBAAgB,GAAhB,wBAAgB,KAAhB,wBAAgB,QAQ3B;AAED,IAAY,mBAKX;AALD,WAAY,mBAAmB;IAC7B,mEAAW,CAAA;IACX,+DAAS,CAAA;IACT,iEAAU,CAAA;IACV,+EAAiB,CAAA;AACnB,CAAC,EALW,mBAAmB,GAAnB,2BAAmB,KAAnB,2BAAmB,QAK9B;AAED,IAAY,YAQX;AARD,WAAY,YAAY;IACtB,qDAAW,CAAA;IACX,+DAAgB,CAAA;IAChB,iFAAyB,CAAA;IACzB,iGAAiC,CAAA;IACjC,+EAAwB,CAAA;IACxB,mEAAkB,CAAA;IAClB,+FAAgC,CAAA;AAClC,CAAC,EARW,YAAY,GAAZ,oBAAY,KAAZ,oBAAY,QAQvB;AAED,IAAY,kBAKX;AALD,WAAY,kBAAkB;IAC5B,iEAAW,CAAA;IACX,yDAAO,CAAA;IACP,2DAAQ,CAAA;IACR,6DAAS,CAAA;AACX,CAAC,EALW,kBAAkB,GAAlB,0BAAkB,KAAlB,0BAAkB,QAK7B;AAED,IAAY,iBAcX;AAdD,WAAY,iBAAiB;IAC3B,+DAAW,CAAA;IACX,uDAAO,CAAA;IACP,uDAAO,CAAA;IACP,yDAAQ,CAAA;IACR,2DAAS,CAAA;IACT,6DAAU,CAAA;IACV,6DAAU,CAAA;IACV,2DAAS,CAAA;IACT,iEAAY,CAAA;IACZ,6EAAkB,CAAA;IAClB,kFAAqB,CAAA;IACrB,4EAAkB,CAAA;IAClB,kFAAqB,CAAA;AACvB,CAAC,EAdW,iBAAiB,GAAjB,yBAAiB,KAAjB,yBAAiB,QAc5B;AAED,IAAY,oBAMX;AAND,WAAY,oBAAoB;IAC9B,qEAAW,CAAA;IACX,6DAAO,CAAA;IACP,iEAAS,CAAA;IACT,qEAAW,CAAA;IACX,uEAAY,CAAA;AACd,CAAC,EANW,oBAAoB,GAApB,4BAAoB,KAApB,4BAAoB,QAM/B;AAqRD,IAAY,QAMX;AAND,WAAY,QAAQ;IAClB,6CAAW,CAAA;IACX,yCAAS,CAAA;IACT,uCAAQ,CAAA;IACR,uCAAQ,CAAA;IACR,yCAAS,CAAA;AACX,CAAC,EANW,QAAQ,GAAR,gBAAQ,KAAR,gBAAQ,QAMnB;AAkgBD,IAAY,gBAMX;AAND,WAAY,gBAAgB;IAC1B,uDAAQ,CAAA;IACR,uDAAQ,CAAA;IACR,2DAAU,CAAA;IACV,qDAAO,CAAA;IACP,uDAAQ,CAAA;AACV,CAAC,EANW,gBAAgB,GAAhB,wBAAgB,KAAhB,wBAAgB,QAM3B","sourcesContent":["/**\n * Do NOT add NestJS logic to this interface.  It is meant to ONLY represent the types for the kafkajs package.\n *\n * @see https://github.com/tulios/kafkajs/blob/master/types/index.d.ts\n *\n * @publicApi\n *\n */\n\n/// <reference types=\"node\" />\nimport * as net from 'net';\nimport * as tls from 'tls';\n\ntype Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };\ntype XOR<T, U> = T | U extends object\n  ? (Without<T, U> & U) | (Without<U, T> & T)\n  : T | U;\n\nexport declare class Kafka {\n  constructor(config: KafkaConfig);\n  producer(config?: ProducerConfig): Producer;\n  consumer(config: ConsumerConfig): Consumer;\n  admin(config?: AdminConfig): Admin;\n  logger(): Logger;\n}\n\nexport type BrokersFunction = () => string[] | Promise<string[]>;\n\ntype SaslAuthenticationRequest = {\n  encode: () => Buffer | Promise<Buffer>;\n};\ntype SaslAuthenticationResponse<ParseResult> = {\n  decode: (rawResponse: Buffer) => Buffer | Promise<Buffer>;\n  parse: (data: Buffer) => ParseResult;\n};\n\ntype Authenticator = {\n  authenticate: () => Promise<void>;\n};\n\ntype AuthenticationProviderArgs = {\n  host: string;\n  port: number;\n  logger: Logger;\n  saslAuthenticate: <ParseResult>(\n    request: SaslAuthenticationRequest,\n    response?: SaslAuthenticationResponse<ParseResult>,\n  ) => Promise<ParseResult | void>;\n};\n\ntype Mechanism = {\n  mechanism: string;\n  authenticationProvider: (args: AuthenticationProviderArgs) => Authenticator;\n};\n\nexport interface KafkaConfig {\n  brokers: string[] | BrokersFunction;\n  ssl?: tls.ConnectionOptions | boolean;\n  sasl?: SASLOptions | Mechanism;\n  clientId?: string;\n  connectionTimeout?: number;\n  authenticationTimeout?: number;\n  reauthenticationThreshold?: number;\n  requestTimeout?: number;\n  enforceRequestTimeout?: boolean;\n  retry?: RetryOptions;\n  socketFactory?: ISocketFactory;\n  logLevel?: logLevel;\n  logCreator?: logCreator;\n}\n\nexport interface ISocketFactoryArgs {\n  host: string;\n  port: number;\n  ssl: tls.ConnectionOptions;\n  onConnect: () => void;\n}\n\nexport type ISocketFactory = (args: ISocketFactoryArgs) => net.Socket;\n\nexport interface OauthbearerProviderResponse {\n  value: string;\n}\n\ntype SASLMechanismOptionsMap = {\n  plain: { username: string; password: string };\n  'scram-sha-256': { username: string; password: string };\n  'scram-sha-512': { username: string; password: string };\n  aws: {\n    authorizationIdentity: string;\n    accessKeyId: string;\n    secretAccessKey: string;\n    sessionToken?: string;\n  };\n  oauthbearer: {\n    oauthBearerProvider: () => Promise<OauthbearerProviderResponse>;\n  };\n};\n\nexport type SASLMechanism = keyof SASLMechanismOptionsMap;\ntype SASLMechanismOptions<T> = T extends SASLMechanism\n  ? { mechanism: T } & SASLMechanismOptionsMap[T]\n  : never;\nexport type SASLOptions = SASLMechanismOptions<SASLMechanism>;\n\nexport interface ProducerConfig {\n  createPartitioner?: ICustomPartitioner;\n  retry?: RetryOptions;\n  metadataMaxAge?: number;\n  allowAutoTopicCreation?: boolean;\n  idempotent?: boolean;\n  transactionalId?: string;\n  transactionTimeout?: number;\n  maxInFlightRequests?: number;\n}\n\nexport interface Message {\n  key?: Buffer | string | null;\n  value: Buffer | string | null;\n  partition?: number;\n  headers?: IHeaders;\n  timestamp?: string;\n}\n\nexport interface PartitionerArgs {\n  topic: string;\n  partitionMetadata: PartitionMetadata[];\n  message: Message;\n}\n\nexport type ICustomPartitioner = () => (args: PartitionerArgs) => number;\nexport type DefaultPartitioner = ICustomPartitioner;\nexport type LegacyPartitioner = ICustomPartitioner;\n\nexport let Partitioners: {\n  DefaultPartitioner: DefaultPartitioner;\n  LegacyPartitioner: LegacyPartitioner;\n  /**\n   * @deprecated Use DefaultPartitioner instead\n   *\n   * The JavaCompatiblePartitioner was renamed DefaultPartitioner\n   * and made to be the default in 2.0.0.\n   */\n  JavaCompatiblePartitioner: DefaultPartitioner;\n};\n\nexport type PartitionMetadata = {\n  partitionErrorCode: number;\n  partitionId: number;\n  leader: number;\n  replicas: number[];\n  isr: number[];\n  offlineReplicas?: number[];\n};\n\nexport interface IHeaders {\n  [key: string]: Buffer | string | (Buffer | string)[] | undefined;\n}\n\nexport interface ConsumerConfig {\n  groupId: string;\n  partitionAssigners?: PartitionAssigner[];\n  metadataMaxAge?: number;\n  sessionTimeout?: number;\n  rebalanceTimeout?: number;\n  heartbeatInterval?: number;\n  maxBytesPerPartition?: number;\n  minBytes?: number;\n  maxBytes?: number;\n  maxWaitTimeInMs?: number;\n  retry?: RetryOptions & {\n    restartOnFailure?: (err: Error) => Promise<boolean>;\n  };\n  allowAutoTopicCreation?: boolean;\n  maxInFlightRequests?: number;\n  readUncommitted?: boolean;\n  rackId?: string;\n}\n\nexport type PartitionAssigner = (config: {\n  cluster: Cluster;\n  groupId: string;\n  logger: Logger;\n}) => Assigner;\n\nexport interface CoordinatorMetadata {\n  errorCode: number;\n  coordinator: {\n    nodeId: number;\n    host: string;\n    port: number;\n  };\n}\n\nexport type Cluster = {\n  getNodeIds(): number[];\n  metadata(): Promise<BrokerMetadata>;\n  removeBroker(options: { host: string; port: number }): void;\n  addMultipleTargetTopics(topics: string[]): Promise<void>;\n  isConnected(): boolean;\n  connect(): Promise<void>;\n  disconnect(): Promise<void>;\n  refreshMetadata(): Promise<void>;\n  refreshMetadataIfNecessary(): Promise<void>;\n  addTargetTopic(topic: string): Promise<void>;\n  findBroker(node: { nodeId: string }): Promise<Broker>;\n  findControllerBroker(): Promise<Broker>;\n  findTopicPartitionMetadata(topic: string): PartitionMetadata[];\n  findLeaderForPartitions(\n    topic: string,\n    partitions: number[],\n  ): { [leader: string]: number[] };\n  findGroupCoordinator(group: { groupId: string }): Promise<Broker>;\n  findGroupCoordinatorMetadata(group: {\n    groupId: string;\n  }): Promise<CoordinatorMetadata>;\n  defaultOffset(config: { fromBeginning: boolean }): number;\n  fetchTopicsOffset(\n    topics: Array<\n      {\n        topic: string;\n        partitions: Array<{ partition: number }>;\n      } & XOR<{ fromBeginning: boolean }, { fromTimestamp: number }>\n    >,\n  ): Promise<TopicOffsets[]>;\n};\n\nexport type Assignment = { [topic: string]: number[] };\n\nexport type GroupMember = { memberId: string; memberMetadata: Buffer };\n\nexport type GroupMemberAssignment = {\n  memberId: string;\n  memberAssignment: Buffer;\n};\n\nexport type GroupState = { name: string; metadata: Buffer };\n\nexport type Assigner = {\n  name: string;\n  version: number;\n  assign(group: {\n    members: GroupMember[];\n    topics: string[];\n  }): Promise<GroupMemberAssignment[]>;\n  protocol(subscription: { topics: string[] }): GroupState;\n};\n\nexport interface RetryOptions {\n  maxRetryTime?: number;\n  initialRetryTime?: number;\n  factor?: number;\n  multiplier?: number;\n  retries?: number;\n  restartOnFailure?: (e: Error) => Promise<boolean>;\n}\n\nexport interface AdminConfig {\n  retry?: RetryOptions;\n}\n\nexport interface ITopicConfig {\n  topic: string;\n  numPartitions?: number;\n  replicationFactor?: number;\n  replicaAssignment?: object[];\n  configEntries?: IResourceConfigEntry[];\n}\n\nexport interface ITopicPartitionConfig {\n  topic: string;\n  count: number;\n  assignments?: Array<Array<number>>;\n}\n\nexport interface ITopicMetadata {\n  name: string;\n  partitions: PartitionMetadata[];\n}\n\nexport enum AclResourceTypes {\n  UNKNOWN = 0,\n  ANY = 1,\n  TOPIC = 2,\n  GROUP = 3,\n  CLUSTER = 4,\n  TRANSACTIONAL_ID = 5,\n  DELEGATION_TOKEN = 6,\n}\n\nexport enum ConfigResourceTypes {\n  UNKNOWN = 0,\n  TOPIC = 2,\n  BROKER = 4,\n  BROKER_LOGGER = 8,\n}\n\nexport enum ConfigSource {\n  UNKNOWN = 0,\n  TOPIC_CONFIG = 1,\n  DYNAMIC_BROKER_CONFIG = 2,\n  DYNAMIC_DEFAULT_BROKER_CONFIG = 3,\n  STATIC_BROKER_CONFIG = 4,\n  DEFAULT_CONFIG = 5,\n  DYNAMIC_BROKER_LOGGER_CONFIG = 6,\n}\n\nexport enum AclPermissionTypes {\n  UNKNOWN = 0,\n  ANY = 1,\n  DENY = 2,\n  ALLOW = 3,\n}\n\nexport enum AclOperationTypes {\n  UNKNOWN = 0,\n  ANY = 1,\n  ALL = 2,\n  READ = 3,\n  WRITE = 4,\n  CREATE = 5,\n  DELETE = 6,\n  ALTER = 7,\n  DESCRIBE = 8,\n  CLUSTER_ACTION = 9,\n  DESCRIBE_CONFIGS = 10,\n  ALTER_CONFIGS = 11,\n  IDEMPOTENT_WRITE = 12,\n}\n\nexport enum ResourcePatternTypes {\n  UNKNOWN = 0,\n  ANY = 1,\n  MATCH = 2,\n  LITERAL = 3,\n  PREFIXED = 4,\n}\n\nexport interface ResourceConfigQuery {\n  type: ConfigResourceTypes;\n  name: string;\n  configNames?: string[];\n}\n\nexport interface ConfigEntries {\n  configName: string;\n  configValue: string;\n  isDefault: boolean;\n  configSource: ConfigSource;\n  isSensitive: boolean;\n  readOnly: boolean;\n  configSynonyms: ConfigSynonyms[];\n}\n\nexport interface ConfigSynonyms {\n  configName: string;\n  configValue: string;\n  configSource: ConfigSource;\n}\n\nexport interface DescribeConfigResponse {\n  resources: {\n    configEntries: ConfigEntries[];\n    errorCode: number;\n    errorMessage: string;\n    resourceName: string;\n    resourceType: ConfigResourceTypes;\n  }[];\n  throttleTime: number;\n}\n\nexport interface IResourceConfigEntry {\n  name: string;\n  value: string;\n}\n\nexport interface IResourceConfig {\n  type: ConfigResourceTypes;\n  name: string;\n  configEntries: IResourceConfigEntry[];\n}\n\ntype ValueOf<T> = T[keyof T];\n\nexport type AdminEvents = {\n  CONNECT: 'admin.connect';\n  DISCONNECT: 'admin.disconnect';\n  REQUEST: 'admin.network.request';\n  REQUEST_TIMEOUT: 'admin.network.request_timeout';\n  REQUEST_QUEUE_SIZE: 'admin.network.request_queue_size';\n};\n\nexport interface InstrumentationEvent<T> {\n  id: string;\n  type: string;\n  timestamp: number;\n  payload: T;\n}\n\nexport type RemoveInstrumentationEventListener<T> = () => void;\n\nexport type ConnectEvent = InstrumentationEvent<null>;\nexport type DisconnectEvent = InstrumentationEvent<null>;\nexport type RequestEvent = InstrumentationEvent<{\n  apiKey: number;\n  apiName: string;\n  apiVersion: number;\n  broker: string;\n  clientId: string;\n  correlationId: number;\n  createdAt: number;\n  duration: number;\n  pendingDuration: number;\n  sentAt: number;\n  size: number;\n}>;\nexport type RequestTimeoutEvent = InstrumentationEvent<{\n  apiKey: number;\n  apiName: string;\n  apiVersion: number;\n  broker: string;\n  clientId: string;\n  correlationId: number;\n  createdAt: number;\n  pendingDuration: number;\n  sentAt: number;\n}>;\nexport type RequestQueueSizeEvent = InstrumentationEvent<{\n  broker: string;\n  clientId: string;\n  queueSize: number;\n}>;\n\nexport type SeekEntry = PartitionOffset;\n\nexport type FetchOffsetsPartition = PartitionOffset & {\n  metadata: string | null;\n};\nexport interface Acl {\n  principal: string;\n  host: string;\n  operation: AclOperationTypes;\n  permissionType: AclPermissionTypes;\n}\n\nexport interface AclResource {\n  resourceType: AclResourceTypes;\n  resourceName: string;\n  resourcePatternType: ResourcePatternTypes;\n}\n\nexport type AclEntry = Acl & AclResource;\n\nexport type DescribeAclResource = AclResource & {\n  acls: Acl[];\n};\n\nexport interface DescribeAclResponse {\n  throttleTime: number;\n  errorCode: number;\n  errorMessage?: string;\n  resources: DescribeAclResource[];\n}\n\nexport interface AclFilter {\n  resourceType: AclResourceTypes;\n  resourceName?: string;\n  resourcePatternType: ResourcePatternTypes;\n  principal?: string;\n  host?: string;\n  operation: AclOperationTypes;\n  permissionType: AclPermissionTypes;\n}\n\nexport interface MatchingAcl {\n  errorCode: number;\n  errorMessage?: string;\n  resourceType: AclResourceTypes;\n  resourceName: string;\n  resourcePatternType: ResourcePatternTypes;\n  principal: string;\n  host: string;\n  operation: AclOperationTypes;\n  permissionType: AclPermissionTypes;\n}\n\nexport interface DeleteAclFilterResponses {\n  errorCode: number;\n  errorMessage?: string;\n  matchingAcls: MatchingAcl[];\n}\n\nexport interface DeleteAclResponse {\n  throttleTime: number;\n  filterResponses: DeleteAclFilterResponses[];\n}\n\nexport type Admin = {\n  connect(): Promise<void>;\n  disconnect(): Promise<void>;\n  listTopics(): Promise<string[]>;\n  createTopics(options: {\n    validateOnly?: boolean;\n    waitForLeaders?: boolean;\n    timeout?: number;\n    topics: ITopicConfig[];\n  }): Promise<boolean>;\n  deleteTopics(options: { topics: string[]; timeout?: number }): Promise<void>;\n  createPartitions(options: {\n    validateOnly?: boolean;\n    timeout?: number;\n    topicPartitions: ITopicPartitionConfig[];\n  }): Promise<boolean>;\n  fetchTopicMetadata(options?: {\n    topics: string[];\n  }): Promise<{ topics: Array<ITopicMetadata> }>;\n  fetchOffsets(options: {\n    groupId: string;\n    topics?: string[];\n    resolveOffsets?: boolean;\n  }): Promise<Array<{ topic: string; partitions: FetchOffsetsPartition[] }>>;\n  fetchTopicOffsets(\n    topic: string,\n  ): Promise<Array<SeekEntry & { high: string; low: string }>>;\n  fetchTopicOffsetsByTimestamp(\n    topic: string,\n    timestamp?: number,\n  ): Promise<Array<SeekEntry>>;\n  describeCluster(): Promise<{\n    brokers: Array<{ nodeId: number; host: string; port: number }>;\n    controller: number | null;\n    clusterId: string;\n  }>;\n  setOffsets(options: {\n    groupId: string;\n    topic: string;\n    partitions: SeekEntry[];\n  }): Promise<void>;\n  resetOffsets(options: {\n    groupId: string;\n    topic: string;\n    earliest: boolean;\n  }): Promise<void>;\n  describeConfigs(configs: {\n    resources: ResourceConfigQuery[];\n    includeSynonyms: boolean;\n  }): Promise<DescribeConfigResponse>;\n  alterConfigs(configs: {\n    validateOnly: boolean;\n    resources: IResourceConfig[];\n  }): Promise<any>;\n  listGroups(): Promise<{ groups: GroupOverview[] }>;\n  deleteGroups(groupIds: string[]): Promise<DeleteGroupsResult[]>;\n  describeGroups(groupIds: string[]): Promise<GroupDescriptions>;\n  describeAcls(options: AclFilter): Promise<DescribeAclResponse>;\n  deleteAcls(options: { filters: AclFilter[] }): Promise<DeleteAclResponse>;\n  createAcls(options: { acl: AclEntry[] }): Promise<boolean>;\n  deleteTopicRecords(options: {\n    topic: string;\n    partitions: SeekEntry[];\n  }): Promise<void>;\n  logger(): Logger;\n  on(\n    eventName: AdminEvents['CONNECT'],\n    listener: (event: ConnectEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: AdminEvents['DISCONNECT'],\n    listener: (event: DisconnectEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: AdminEvents['REQUEST'],\n    listener: (event: RequestEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: AdminEvents['REQUEST_QUEUE_SIZE'],\n    listener: (event: RequestQueueSizeEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: AdminEvents['REQUEST_TIMEOUT'],\n    listener: (event: RequestTimeoutEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ValueOf<AdminEvents>,\n    listener: (event: InstrumentationEvent<any>) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  readonly events: AdminEvents;\n};\n\nexport let PartitionAssigners: { roundRobin: PartitionAssigner };\n\nexport interface ISerializer<T> {\n  encode(value: T): Buffer;\n  decode(buffer: Buffer): T | null;\n}\n\nexport type MemberMetadata = {\n  version: number;\n  topics: string[];\n  userData: Buffer;\n};\n\nexport type MemberAssignment = {\n  version: number;\n  assignment: Assignment;\n  userData: Buffer;\n};\n\nexport let AssignerProtocol: {\n  MemberMetadata: ISerializer<MemberMetadata>;\n  MemberAssignment: ISerializer<MemberAssignment>;\n};\n\nexport enum logLevel {\n  NOTHING = 0,\n  ERROR = 1,\n  WARN = 2,\n  INFO = 4,\n  DEBUG = 5,\n}\n\nexport interface LogEntry {\n  namespace: string;\n  level: logLevel;\n  label: string;\n  log: LoggerEntryContent;\n}\n\nexport interface LoggerEntryContent {\n  readonly timestamp: string;\n  readonly message: string;\n  [key: string]: any;\n}\n\nexport type logCreator = (logLevel: logLevel) => (entry: LogEntry) => void;\n\nexport type Logger = {\n  info: (message: string, extra?: object) => void;\n  error: (message: string, extra?: object) => void;\n  warn: (message: string, extra?: object) => void;\n  debug: (message: string, extra?: object) => void;\n\n  namespace: (namespace: string, logLevel?: logLevel) => Logger;\n  setLogLevel: (logLevel: logLevel) => void;\n};\n\nexport interface BrokerMetadata {\n  brokers: Array<{ nodeId: number; host: string; port: number; rack?: string }>;\n  topicMetadata: Array<{\n    topicErrorCode: number;\n    topic: string;\n    partitionMetadata: PartitionMetadata[];\n  }>;\n}\n\nexport interface ApiVersions {\n  [apiKey: number]: {\n    minVersion: number;\n    maxVersion: number;\n  };\n}\n\nexport type Broker = {\n  isConnected(): boolean;\n  connect(): Promise<void>;\n  disconnect(): Promise<void>;\n  apiVersions(): Promise<ApiVersions>;\n  metadata(topics: string[]): Promise<BrokerMetadata>;\n  describeGroups: (options: { groupIds: string[] }) => Promise<any>;\n  offsetCommit(request: {\n    groupId: string;\n    groupGenerationId: number;\n    memberId: string;\n    retentionTime?: number;\n    topics: TopicOffsets[];\n  }): Promise<any>;\n  offsetFetch(request: { groupId: string; topics: TopicOffsets[] }): Promise<{\n    responses: TopicOffsets[];\n  }>;\n  fetch(request: {\n    replicaId?: number;\n    isolationLevel?: number;\n    maxWaitTime?: number;\n    minBytes?: number;\n    maxBytes?: number;\n    topics: Array<{\n      topic: string;\n      partitions: Array<{\n        partition: number;\n        fetchOffset: string;\n        maxBytes: number;\n      }>;\n    }>;\n    rackId?: string;\n  }): Promise<any>;\n  produce(request: {\n    topicData: Array<{\n      topic: string;\n      partitions: Array<{\n        partition: number;\n        firstSequence?: number;\n        messages: Message[];\n      }>;\n    }>;\n    transactionalId?: string;\n    producerId?: number;\n    producerEpoch?: number;\n    acks?: number;\n    timeout?: number;\n    compression?: CompressionTypes;\n  }): Promise<any>;\n};\n\ninterface MessageSetEntry {\n  key: Buffer | null;\n  value: Buffer | null;\n  timestamp: string;\n  attributes: number;\n  offset: string;\n  size: number;\n  headers?: never;\n}\n\ninterface RecordBatchEntry {\n  key: Buffer | null;\n  value: Buffer | null;\n  timestamp: string;\n  attributes: number;\n  offset: string;\n  headers: IHeaders;\n  size?: never;\n}\n\nexport type KafkaMessage = MessageSetEntry | RecordBatchEntry;\n\nexport interface ProducerRecord {\n  topic: string;\n  messages: Message[];\n  acks?: number;\n  timeout?: number;\n  compression?: CompressionTypes;\n}\n\nexport type RecordMetadata = {\n  topicName: string;\n  partition: number;\n  errorCode: number;\n  offset?: string;\n  timestamp?: string;\n  baseOffset?: string;\n  logAppendTime?: string;\n  logStartOffset?: string;\n};\n\nexport interface TopicMessages {\n  topic: string;\n  messages: Message[];\n}\n\nexport interface ProducerBatch {\n  acks?: number;\n  timeout?: number;\n  compression?: CompressionTypes;\n  topicMessages?: TopicMessages[];\n}\n\nexport interface PartitionOffset {\n  partition: number;\n  offset: string;\n}\n\nexport interface TopicOffsets {\n  topic: string;\n  partitions: PartitionOffset[];\n}\n\nexport interface Offsets {\n  topics: TopicOffsets[];\n}\n\ntype Sender = {\n  send(record: ProducerRecord): Promise<RecordMetadata[]>;\n  sendBatch(batch: ProducerBatch): Promise<RecordMetadata[]>;\n};\n\nexport type ProducerEvents = {\n  CONNECT: 'producer.connect';\n  DISCONNECT: 'producer.disconnect';\n  REQUEST: 'producer.network.request';\n  REQUEST_TIMEOUT: 'producer.network.request_timeout';\n  REQUEST_QUEUE_SIZE: 'producer.network.request_queue_size';\n};\n\nexport type Producer = Sender & {\n  connect(): Promise<void>;\n  disconnect(): Promise<void>;\n  isIdempotent(): boolean;\n  readonly events: ProducerEvents;\n  on(\n    eventName: ProducerEvents['CONNECT'],\n    listener: (event: ConnectEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ProducerEvents['DISCONNECT'],\n    listener: (event: DisconnectEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ProducerEvents['REQUEST'],\n    listener: (event: RequestEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ProducerEvents['REQUEST_QUEUE_SIZE'],\n    listener: (event: RequestQueueSizeEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ProducerEvents['REQUEST_TIMEOUT'],\n    listener: (event: RequestTimeoutEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ValueOf<ProducerEvents>,\n    listener: (event: InstrumentationEvent<any>) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  transaction(): Promise<Transaction>;\n  logger(): Logger;\n};\n\nexport type Transaction = Sender & {\n  sendOffsets(offsets: Offsets & { consumerGroupId: string }): Promise<void>;\n  commit(): Promise<void>;\n  abort(): Promise<void>;\n  isActive(): boolean;\n};\n\nexport type ConsumerGroup = {\n  groupId: string;\n  generationId: number;\n  memberId: string;\n  coordinator: Broker;\n};\n\nexport type MemberDescription = {\n  clientHost: string;\n  clientId: string;\n  memberId: string;\n  memberAssignment: Buffer;\n  memberMetadata: Buffer;\n};\n\n// See https://github.com/apache/kafka/blob/2.4.0/clients/src/main/java/org/apache/kafka/common/ConsumerGroupState.java#L25\nexport type ConsumerGroupState =\n  | 'Unknown'\n  | 'PreparingRebalance'\n  | 'CompletingRebalance'\n  | 'Stable'\n  | 'Dead'\n  | 'Empty';\n\nexport type GroupDescription = {\n  groupId: string;\n  members: MemberDescription[];\n  protocol: string;\n  protocolType: string;\n  state: ConsumerGroupState;\n};\n\nexport type GroupDescriptions = {\n  groups: GroupDescription[];\n};\n\nexport type TopicPartitions = { topic: string; partitions: number[] };\n\nexport type TopicPartition = {\n  topic: string;\n  partition: number;\n};\nexport type TopicPartitionOffset = TopicPartition & {\n  offset: string;\n};\nexport type TopicPartitionOffsetAndMetadata = TopicPartitionOffset & {\n  metadata?: string | null;\n};\n\nexport type Batch = {\n  topic: string;\n  partition: number;\n  highWatermark: string;\n  messages: KafkaMessage[];\n  isEmpty(): boolean;\n  firstOffset(): string | null;\n  lastOffset(): string;\n  offsetLag(): string;\n  offsetLagLow(): string;\n};\n\nexport type GroupOverview = {\n  groupId: string;\n  protocolType: string;\n};\n\nexport type DeleteGroupsResult = {\n  groupId: string;\n  errorCode?: number;\n  error?: KafkaJSProtocolError;\n};\n\nexport type ConsumerEvents = {\n  HEARTBEAT: 'consumer.heartbeat';\n  COMMIT_OFFSETS: 'consumer.commit_offsets';\n  GROUP_JOIN: 'consumer.group_join';\n  FETCH_START: 'consumer.fetch_start';\n  FETCH: 'consumer.fetch';\n  START_BATCH_PROCESS: 'consumer.start_batch_process';\n  END_BATCH_PROCESS: 'consumer.end_batch_process';\n  CONNECT: 'consumer.connect';\n  DISCONNECT: 'consumer.disconnect';\n  STOP: 'consumer.stop';\n  CRASH: 'consumer.crash';\n  REBALANCING: 'consumer.rebalancing';\n  RECEIVED_UNSUBSCRIBED_TOPICS: 'consumer.received_unsubscribed_topics';\n  REQUEST: 'consumer.network.request';\n  REQUEST_TIMEOUT: 'consumer.network.request_timeout';\n  REQUEST_QUEUE_SIZE: 'consumer.network.request_queue_size';\n};\nexport type ConsumerHeartbeatEvent = InstrumentationEvent<{\n  groupId: string;\n  memberId: string;\n  groupGenerationId: number;\n}>;\nexport type ConsumerCommitOffsetsEvent = InstrumentationEvent<{\n  groupId: string;\n  memberId: string;\n  groupGenerationId: number;\n  topics: TopicOffsets[];\n}>;\nexport interface IMemberAssignment {\n  [key: string]: number[];\n}\nexport type ConsumerGroupJoinEvent = InstrumentationEvent<{\n  duration: number;\n  groupId: string;\n  isLeader: boolean;\n  leaderId: string;\n  groupProtocol: string;\n  memberId: string;\n  memberAssignment: IMemberAssignment;\n}>;\nexport type ConsumerFetchStartEvent = InstrumentationEvent<{ nodeId: number }>;\nexport type ConsumerFetchEvent = InstrumentationEvent<{\n  numberOfBatches: number;\n  duration: number;\n  nodeId: number;\n}>;\ninterface IBatchProcessEvent {\n  topic: string;\n  partition: number;\n  highWatermark: string;\n  offsetLag: string;\n  offsetLagLow: string;\n  batchSize: number;\n  firstOffset: string;\n  lastOffset: string;\n}\nexport type ConsumerStartBatchProcessEvent =\n  InstrumentationEvent<IBatchProcessEvent>;\nexport type ConsumerEndBatchProcessEvent = InstrumentationEvent<\n  IBatchProcessEvent & { duration: number }\n>;\nexport type ConsumerCrashEvent = InstrumentationEvent<{\n  error: Error;\n  groupId: string;\n  restart: boolean;\n}>;\nexport type ConsumerRebalancingEvent = InstrumentationEvent<{\n  groupId: string;\n  memberId: string;\n}>;\nexport type ConsumerReceivedUnsubscribedTopicsEvent = InstrumentationEvent<{\n  groupId: string;\n  generationId: number;\n  memberId: string;\n  assignedTopics: string[];\n  topicsSubscribed: string[];\n  topicsNotSubscribed: string[];\n}>;\n\nexport interface OffsetsByTopicPartition {\n  topics: TopicOffsets[];\n}\n\nexport interface EachMessagePayload {\n  topic: string;\n  partition: number;\n  message: KafkaMessage;\n  heartbeat(): Promise<void>;\n  pause(): () => void;\n}\n\nexport interface EachBatchPayload {\n  batch: Batch;\n  resolveOffset(offset: string): void;\n  heartbeat(): Promise<void>;\n  pause(): () => void;\n  commitOffsetsIfNecessary(offsets?: Offsets): Promise<void>;\n  uncommittedOffsets(): OffsetsByTopicPartition;\n  isRunning(): boolean;\n  isStale(): boolean;\n}\n\n/**\n * Type alias to keep compatibility with @types/kafkajs\n * @see https://github.com/DefinitelyTyped/DefinitelyTyped/blob/712ad9d59ccca6a3cc92f347fea0d1c7b02f5eeb/types/kafkajs/index.d.ts#L321-L325\n */\nexport type ConsumerEachMessagePayload = EachMessagePayload;\n\n/**\n * Type alias to keep compatibility with @types/kafkajs\n * @see https://github.com/DefinitelyTyped/DefinitelyTyped/blob/712ad9d59ccca6a3cc92f347fea0d1c7b02f5eeb/types/kafkajs/index.d.ts#L327-L336\n */\nexport type ConsumerEachBatchPayload = EachBatchPayload;\n\nexport type EachBatchHandler = (payload: EachBatchPayload) => Promise<void>;\nexport type EachMessageHandler = (payload: EachMessagePayload) => Promise<void>;\n\nexport type ConsumerRunConfig = {\n  autoCommit?: boolean;\n  autoCommitInterval?: number | null;\n  autoCommitThreshold?: number | null;\n  eachBatchAutoResolve?: boolean;\n  partitionsConsumedConcurrently?: number;\n  eachBatch?: EachBatchHandler;\n  eachMessage?: EachMessageHandler;\n};\n\n/**\n * @deprecated Replaced by ConsumerSubscribeTopics\n */\nexport type ConsumerSubscribeTopic = {\n  topic: string | RegExp;\n  fromBeginning?: boolean;\n};\nexport type ConsumerSubscribeTopics = {\n  topics: (string | RegExp)[];\n  fromBeginning?: boolean;\n};\n\nexport type Consumer = {\n  connect(): Promise<void>;\n  disconnect(): Promise<void>;\n  subscribe(\n    subscription: ConsumerSubscribeTopics | ConsumerSubscribeTopic,\n  ): Promise<void>;\n  stop(): Promise<void>;\n  run(config?: ConsumerRunConfig): Promise<void>;\n  commitOffsets(\n    topicPartitions: Array<TopicPartitionOffsetAndMetadata>,\n  ): Promise<void>;\n  seek(topicPartitionOffset: TopicPartitionOffset): void;\n  describeGroup(): Promise<GroupDescription>;\n  pause(topics: Array<{ topic: string; partitions?: number[] }>): void;\n  paused(): TopicPartitions[];\n  resume(topics: Array<{ topic: string; partitions?: number[] }>): void;\n  on(\n    eventName: ConsumerEvents['HEARTBEAT'],\n    listener: (event: ConsumerHeartbeatEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['COMMIT_OFFSETS'],\n    listener: (event: ConsumerCommitOffsetsEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['GROUP_JOIN'],\n    listener: (event: ConsumerGroupJoinEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['FETCH_START'],\n    listener: (event: ConsumerFetchStartEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['FETCH'],\n    listener: (event: ConsumerFetchEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['START_BATCH_PROCESS'],\n    listener: (event: ConsumerStartBatchProcessEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['END_BATCH_PROCESS'],\n    listener: (event: ConsumerEndBatchProcessEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['CONNECT'],\n    listener: (event: ConnectEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['DISCONNECT'],\n    listener: (event: DisconnectEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['STOP'],\n    listener: (event: InstrumentationEvent<null>) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['CRASH'],\n    listener: (event: ConsumerCrashEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['REBALANCING'],\n    listener: (event: ConsumerRebalancingEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['RECEIVED_UNSUBSCRIBED_TOPICS'],\n    listener: (event: ConsumerReceivedUnsubscribedTopicsEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['REQUEST'],\n    listener: (event: RequestEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['REQUEST_TIMEOUT'],\n    listener: (event: RequestTimeoutEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ConsumerEvents['REQUEST_QUEUE_SIZE'],\n    listener: (event: RequestQueueSizeEvent) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  on(\n    eventName: ValueOf<ConsumerEvents>,\n    listener: (event: InstrumentationEvent<any>) => void,\n  ): RemoveInstrumentationEventListener<typeof eventName>;\n  logger(): Logger;\n  readonly events: ConsumerEvents;\n};\n\nexport enum CompressionTypes {\n  None = 0,\n  GZIP = 1,\n  Snappy = 2,\n  LZ4 = 3,\n  ZSTD = 4,\n}\n\nexport let CompressionCodecs: {\n  [CompressionTypes.GZIP]: () => any;\n  [CompressionTypes.Snappy]: () => any;\n  [CompressionTypes.LZ4]: () => any;\n  [CompressionTypes.ZSTD]: () => any;\n};\n\nexport declare class KafkaJSError extends Error {\n  readonly message: Error['message'];\n  readonly name: string;\n  readonly retriable: boolean;\n  readonly helpUrl?: string;\n  readonly cause?: Error;\n\n  constructor(e: Error | string, metadata?: KafkaJSErrorMetadata);\n}\n\nexport declare class KafkaJSNonRetriableError extends KafkaJSError {\n  constructor(e: Error | string);\n}\n\nexport declare class KafkaJSProtocolError extends KafkaJSError {\n  readonly code: number;\n  readonly type: string;\n  constructor(e: Error | string);\n}\n\nexport declare class KafkaJSOffsetOutOfRange extends KafkaJSProtocolError {\n  readonly topic: string;\n  readonly partition: number;\n  constructor(e: Error | string, metadata?: KafkaJSOffsetOutOfRangeMetadata);\n}\n\nexport declare class KafkaJSNumberOfRetriesExceeded extends KafkaJSNonRetriableError {\n  readonly stack: string;\n  readonly retryCount: number;\n  readonly retryTime: number;\n  constructor(\n    e: Error | string,\n    metadata?: KafkaJSNumberOfRetriesExceededMetadata,\n  );\n}\n\nexport declare class KafkaJSConnectionError extends KafkaJSError {\n  readonly broker: string;\n  constructor(e: Error | string, metadata?: KafkaJSConnectionErrorMetadata);\n}\n\nexport declare class KafkaJSRequestTimeoutError extends KafkaJSError {\n  readonly broker: string;\n  readonly correlationId: number;\n  readonly createdAt: number;\n  readonly sentAt: number;\n  readonly pendingDuration: number;\n  constructor(e: Error | string, metadata?: KafkaJSRequestTimeoutErrorMetadata);\n}\n\nexport declare class KafkaJSMetadataNotLoaded extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSTopicMetadataNotLoaded extends KafkaJSMetadataNotLoaded {\n  readonly topic: string;\n  constructor(\n    e: Error | string,\n    metadata?: KafkaJSTopicMetadataNotLoadedMetadata,\n  );\n}\n\nexport declare class KafkaJSStaleTopicMetadataAssignment extends KafkaJSError {\n  readonly topic: string;\n  readonly unknownPartitions: number;\n  constructor(\n    e: Error | string,\n    metadata?: KafkaJSStaleTopicMetadataAssignmentMetadata,\n  );\n}\n\nexport declare class KafkaJSServerDoesNotSupportApiKey extends KafkaJSNonRetriableError {\n  readonly apiKey: number;\n  readonly apiName: string;\n  constructor(\n    e: Error | string,\n    metadata?: KafkaJSServerDoesNotSupportApiKeyMetadata,\n  );\n}\n\nexport declare class KafkaJSBrokerNotFound extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSPartialMessageError extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSSASLAuthenticationError extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSGroupCoordinatorNotFound extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSNotImplemented extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSTimeout extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSLockTimeout extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSUnsupportedMagicByteInMessageSet extends KafkaJSError {\n  constructor();\n}\n\nexport declare class KafkaJSDeleteGroupsError extends KafkaJSError {\n  readonly groups: DeleteGroupsResult[];\n  constructor(e: Error | string, groups?: KafkaJSDeleteGroupsErrorGroups[]);\n}\n\nexport declare class KafkaJSDeleteTopicRecordsError extends KafkaJSError {\n  constructor(metadata: KafkaJSDeleteTopicRecordsErrorTopic);\n}\n\nexport interface KafkaJSDeleteGroupsErrorGroups {\n  groupId: string;\n  errorCode: number;\n  error: KafkaJSError;\n}\n\nexport interface KafkaJSDeleteTopicRecordsErrorTopic {\n  topic: string;\n  partitions: KafkaJSDeleteTopicRecordsErrorPartition[];\n}\n\nexport interface KafkaJSDeleteTopicRecordsErrorPartition {\n  partition: number;\n  offset: string;\n  error: KafkaJSError;\n}\n\nexport interface KafkaJSErrorMetadata {\n  retriable?: boolean;\n  topic?: string;\n  partitionId?: number;\n  metadata?: PartitionMetadata;\n}\n\nexport interface KafkaJSOffsetOutOfRangeMetadata {\n  topic: string;\n  partition: number;\n}\n\nexport interface KafkaJSNumberOfRetriesExceededMetadata {\n  retryCount: number;\n  retryTime: number;\n}\n\nexport interface KafkaJSConnectionErrorMetadata {\n  broker?: string;\n  code?: string;\n}\n\nexport interface KafkaJSRequestTimeoutErrorMetadata {\n  broker: string;\n  clientId: string;\n  correlationId: number;\n  createdAt: number;\n  sentAt: number;\n  pendingDuration: number;\n}\n\nexport interface KafkaJSTopicMetadataNotLoadedMetadata {\n  topic: string;\n}\n\nexport interface KafkaJSStaleTopicMetadataAssignmentMetadata {\n  topic: string;\n  unknownPartitions: PartitionMetadata[];\n}\n\nexport interface KafkaJSServerDoesNotSupportApiKeyMetadata {\n  apiKey: number;\n  apiName: string;\n}\n"]}